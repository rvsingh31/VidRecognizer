{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import keras\n",
    "from models import TSN\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, filepath, batch_size, ffpath, segments = 3, test=False):\n",
    "        self.filenames = list()\n",
    "        self.labels = list()\n",
    "        self.batch_size = batch_size\n",
    "        self.filepath = filepath\n",
    "        self.ffpath = ffpath\n",
    "        self.segments = segments\n",
    "        \n",
    "        with open(self.filepath,\"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                arr = line.split(\" \")\n",
    "                self.filenames.append(arr[0])\n",
    "                self.labels.append(int(arr[1].strip()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)//self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.filenames))]\n",
    "        batch_y = self.labels[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.filenames))]\n",
    "\n",
    "        Xframes = defaultdict(list)\n",
    "        Y = list()\n",
    "        Xflows = defaultdict(list)\n",
    "        for index,each in enumerate(batch_x):\n",
    "            infopath = os.path.join(self.ffpath,each,\"info.txt\")\n",
    "            imgpath = os.path.join(self.ffpath,each,\"frames\")\n",
    "            flowspath = os.path.join(self.ffpath,each,\"flows\")\n",
    "            f = open(infopath,\"r\")\n",
    "            total_frames = int(f.readlines()[0].strip().split(':')[1])\n",
    "            f.close()\n",
    "            idxs = []\n",
    "            base = total_frames//self.segments\n",
    "            low = 1\n",
    "            num_frames = 2\n",
    "            for _ in range(self.segments):\n",
    "                high = min(low + base, total_frames)\n",
    "                idxs.extend(np.random.randint(low, high, num_frames))\n",
    "                low = high + 1 \n",
    "            frames = self.getFrames(idxs, imgpath)\n",
    "            flows = self.getFlows(idxs, flowspath)\n",
    "            \n",
    "            for i in range(len(frames)):\n",
    "                Xframes[i%self.segments].append(frames[i])\n",
    "                        \n",
    "            for i in range(len(flows)):\n",
    "                Xflows[i%self.segments].append(flows[i])\n",
    "                \n",
    "            Y.extend([batch_y[index]]*(num_frames))\n",
    "            \n",
    "        finalX = dict()\n",
    "        i = 1\n",
    "        for key in Xframes.keys():\n",
    "            finalX['input_'+str(i)] = np.array(Xframes[key])\n",
    "            i += 1\n",
    "        for key in Xflows.keys():\n",
    "            finalX['input_'+str(i)] = np.array(Xflows[key])\n",
    "            i += 1\n",
    "            \n",
    "        finalY = {'output':self.one_hot_encode(np.array(Y))}\n",
    "\n",
    "        return (finalX,finalY)\n",
    "    \n",
    "    def one_hot_encode(self,data, classes = 101):\n",
    "        \"\"\"\n",
    "        :param data: data to be one hot encoded\n",
    "        :return: np array with one hot encoding\n",
    "        \"\"\"\n",
    "        labels = np.zeros((data.size, classes))\n",
    "        labels[np.arange(data.size), data - 1] = 1\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def getFlows(self,idxs, flowspath):\n",
    "\n",
    "        stack = list()\n",
    "        for i in idxs:\n",
    "            f1 = \"flow_x_\"+str(i)+\".jpg\"\n",
    "            f2 = \"flow_y_\"+str(i)+\".jpg\"\n",
    "            grayx = self.readImg(os.path.join(flowspath,f1))\n",
    "            grayy = self.readImg(os.path.join(flowspath,f2))\n",
    "            img = np.stack((grayx,grayy),axis = 2)\n",
    "            img = np.squeeze(img,axis = 3)\n",
    "            stack.append(img)\n",
    "            \n",
    "        return np.array(stack)\n",
    "    \n",
    "    def readImg(self,path):\n",
    "        img = cv2.imread(path)\n",
    "        grayimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        grayimg = np.expand_dims(grayimg,axis = 2)\n",
    "        return grayimg\n",
    "    \n",
    "    \n",
    "    def getFrames(self,idxs, imgpath):\n",
    "\n",
    "        stack = list()\n",
    "        for i in idxs:\n",
    "            framename = \"frame_\"+str(i)+\".jpg\"\n",
    "            stack.append(self.readImg(os.path.join(imgpath,framename)))\n",
    "            \n",
    "        return np.array(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGeneratorOntheFly(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, datapath, filepath, batch_size, segments = 3, test=False):\n",
    "        self.filenames = list()\n",
    "        self.labels = list()\n",
    "        self.batch_size = batch_size\n",
    "        self.datapath = datapath\n",
    "        self.filepath = filepath\n",
    "        self.segments = segments\n",
    "        \n",
    "        with open(self.filepath,\"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                arr = line.split(\" \")\n",
    "                self.filenames.append(arr[0])\n",
    "                self.labels.append(int(arr[1].strip()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)//self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.filenames))]\n",
    "        batch_y = self.labels[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.filenames))]\n",
    "\n",
    "        Xframes = defaultdict(list)\n",
    "        Y = list()\n",
    "        Xflows = defaultdict(list)\n",
    "        for index,each in enumerate(batch_x):\n",
    "            cap = cv2.VideoCapture(os.path.join(datapath,each))\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            idxs = []\n",
    "            base = total_frames//self.segments\n",
    "            low = 1\n",
    "            for _ in range(self.segments):\n",
    "                high = min(low + base, total_frames)\n",
    "                idxs.append(np.random.randint(low, high,1)[0])\n",
    "                low = high + 1\n",
    "            frames,flows = self.getFramesandFlows(idxs, cap)\n",
    "            for i in range(self.segments):\n",
    "                Xframes[i].append(frames[i])\n",
    "                \n",
    "            for i in range(self.segments):\n",
    "                Xflows[i].append(flows[i])\n",
    "            \n",
    "            Y.append(batch_y[index])\n",
    "            \n",
    "        finalX = dict()\n",
    "        i = 1\n",
    "        for key in Xframes.keys():\n",
    "            finalX['input_'+str(i)] = np.array(Xframes[key])\n",
    "            i += 1\n",
    "        for key in Xflows.keys():\n",
    "            finalX['input_'+str(i)] = np.array(Xflows[key])\n",
    "            i += 1\n",
    "            \n",
    "        finalY = {'output':self.one_hot_encode(np.array(Y))}\n",
    "\n",
    "        return (finalX,finalY)\n",
    "    \n",
    "    def one_hot_encode(self,data, classes = 101):\n",
    "        \"\"\"\n",
    "        :param data: data to be one hot encoded\n",
    "        :return: np array with one hot encoding\n",
    "        \"\"\"\n",
    "        labels = np.zeros((data.size, classes))\n",
    "        labels[np.arange(data.size), data - 1] = 1\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def getFramesandFlows(self,idxs,cap):\n",
    "        \n",
    "        frames = list()\n",
    "        flows = list()\n",
    "        for each in idxs:\n",
    "            \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,each)\n",
    "            _,thisFrame = cap.read()\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,each-1)\n",
    "            _,prevFrame = cap.read()\n",
    "            \n",
    "            thisFrame = cv2.resize(thisFrame,(224,224))\n",
    "            prevFrame = cv2.resize(prevFrame,(224,224))\n",
    "            \n",
    "            thisFrame  = cv2.cvtColor(thisFrame,cv2.COLOR_BGR2GRAY)\n",
    "            prevFrame  = cv2.cvtColor(prevFrame,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "            flow = optical_flow.calc(prevFrame, thisFrame, None)\n",
    "            flow_x = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
    "            flow_y = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
    "            \n",
    "            thisFrame = np.expand_dims(thisFrame,axis = 2)\n",
    "            flow_x = np.expand_dims(flow_x, axis = 2)\n",
    "            flow_y = np.expand_dims(flow_y, axis = 2)\n",
    "            \n",
    "            thisFlow = np.stack((flow_x,flow_y),axis = 2)\n",
    "            thisFlow = np.squeeze(thisFlow,axis = 3)\n",
    "            \n",
    "            frames.append(thisFrame)\n",
    "            flows.append(thisFlow)\n",
    "        \n",
    "        return np.array(frames), np.array(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folderpath = \"../ucfTrainTestlist\"\n",
    "# datapath = \"../../UCF-101\"\n",
    "# filename = \"trainlist01.txt\"\n",
    "# dg = dataGeneratorNew(datapath,os.path.join(folderpath,filename),batch_size = 128)\n",
    "\n",
    "\n",
    "\n",
    "folderpath = \"../ucfTrainTestlist\"\n",
    "filenameTrain = \"custom3Train.txt\"\n",
    "filenameVal = \"custom3Val.txt\"\n",
    "\n",
    "filepath = os.path.join(folderpath,filenameTrain)\n",
    "ffpath = os.path.join(\"../../VidRecognizer/FramesFlows/custom3\")\n",
    "dgTrain = dataGenerator(filepath,16,ffpath)\n",
    "\n",
    "filepath = os.path.join(folderpath,filenameVal)\n",
    "ffpath = os.path.join(\"../../VidRecognizer/FramesFlows/custom3\")\n",
    "dgVal = dataGenerator(filepath,16,ffpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = dgTrain.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1]['output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Create and Compile model\n",
    "K.clear_session()\n",
    "model = TSN()\n",
    "model.compile(optimizer= keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpointing\n",
    "\n",
    "filepath=\"../model_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', min_delta=1, patience = 10)\n",
    "callbacks_list = [checkpoint,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 105s 6s/step - loss: 7.4750 - acc: 0.0226 - val_loss: 6.6189 - val_acc: 0.0156\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01562, saving model to ../model_checkpoints/weights-improvement-01-0.02.hdf5\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 15s 852ms/step - loss: 6.2627 - acc: 0.0226 - val_loss: 6.9598 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.01562\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 15s 849ms/step - loss: 9.1079 - acc: 0.0208 - val_loss: 10.4063 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.01562\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 15s 848ms/step - loss: 10.6552 - acc: 0.0191 - val_loss: 8.9244 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.01562\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 15s 847ms/step - loss: 8.8282 - acc: 0.0295 - val_loss: 8.7951 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.01562\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 15s 852ms/step - loss: 7.4388 - acc: 0.0278 - val_loss: 8.3156 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.01562\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 15s 854ms/step - loss: 6.9421 - acc: 0.0156 - val_loss: 7.7469 - val_acc: 0.0052\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.01562\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 15s 858ms/step - loss: 7.3621 - acc: 0.0208 - val_loss: 10.0704 - val_acc: 0.0208\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.01562 to 0.02083, saving model to ../model_checkpoints/weights-improvement-08-0.02.hdf5\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 15s 860ms/step - loss: 11.5514 - acc: 0.0208 - val_loss: 9.0518 - val_acc: 0.0208\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.02083\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 15s 861ms/step - loss: 10.4896 - acc: 0.0243 - val_loss: 9.1983 - val_acc: 0.0208\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.02083\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 15s 856ms/step - loss: 9.5763 - acc: 0.0260 - val_loss: 8.5638 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.02083\n"
     ]
    }
   ],
   "source": [
    "# model.fit([np.array(framesSegments[0]),np.array(framesSegments[1]),np.array(framesSegments[2]),np.array(flows[0]),np.array(flows[1]),np.array(flows[2])],yFramesTrueSegments[0],batch_size = 3, epochs = 1)\n",
    "np.random.seed(0)\n",
    "#Fit generator\n",
    "history = model.fit_generator(dgTrain,epochs = 150,validation_data = dgVal, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
