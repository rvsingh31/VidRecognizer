{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import keras\n",
    "from tsn import TSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for storing the frames\n",
    " \n",
    "splitfiledir = r\"..\\ucfTrainTestlist\"\n",
    "splitfile = \"trainlist01.txt\"\n",
    "splitname = splitfile.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeFramesAndFlows(framesdir,splitfiledir,splitfile,splitname):\n",
    "    \n",
    "    #Read splitfile\n",
    "    lines = open(os.path.join(splitfiledir,splitfile),\"r\")\n",
    "    for line in lines:\n",
    "        arr = line.split(\" \")\n",
    "        vidclass = arr[1] \n",
    "        line = arr[0].split(\"/\")\n",
    "        action = line[0]\n",
    "        filename = line[1]\n",
    "        actionpath = os.path.join(framesdir,splitname,action)\n",
    "        framepath = os.path.join(actionpath,filename,\"frames\")\n",
    "        flowpath = os.path.join(actionpath,filename,\"flows\")\n",
    "        \n",
    "        #Create folder for Action\n",
    "        if not os.path.exists(actionpath):\n",
    "            os.mkdir(actionpath)\n",
    "        \n",
    "        #Create folder for videofile\n",
    "        if not os.path.exists(os.path.join(actionpath,filename)):\n",
    "            os.mkdir(os.path.join(actionpath,filename))\n",
    "        \n",
    "        #Create folder for frames\n",
    "        if not os.path.exists(framepath):\n",
    "            os.mkdir(framepath)\n",
    "            \n",
    "        #Create folder for flows\n",
    "        if not os.path.exists(flowpath):\n",
    "            os.mkdir(flowpath)\n",
    "\n",
    "        #Read video and collect frames, flows\n",
    "        vidcap = cv2.VideoCapture(os.path.join(path,action,filename))\n",
    "        count = 0 \n",
    "        prevFrame = None\n",
    "        nextFrame = None\n",
    "        while True:\n",
    "            success,image = vidcap.read()\n",
    "            #Resize image to remain consistent with BN Inception model\n",
    "            if not success:\n",
    "                break\n",
    "            image = cv2.resize(image,(224,224))\n",
    "            frame = \"frame_%d.jpg\"%count\n",
    "            flow_x = \"flow_x_%d.jpg\"%count\n",
    "            flow_y = \"flow_y_%d.jpg\"%count\n",
    "            framename = os.path.join(framepath,frame)\n",
    "            flowname_x = os.path.join(flowpath,flow_x)\n",
    "            flowname_y = os.path.join(flowpath,flow_y)\n",
    "            if count == 0:\n",
    "                prevFrame = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imwrite(framename,image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            nextFrame = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(framename,image)\n",
    "            optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "            flow = optical_flow.calc(prevFrame, nextFrame, None)\n",
    "            prevFrame = nextFrame\n",
    "            flow[...,0] = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
    "            flow[...,1] = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
    "            cv2.imwrite(flowname_x,flow[...,0])\n",
    "            cv2.imwrite(flowname_y,flow[...,1])\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            count += 1\n",
    "            \n",
    "        filename = os.path.join(actionpath,filename,\"info.txt\")\n",
    "        #Store the frames count in txt file\n",
    "        rate = open(filename,\"w\")\n",
    "        rate.write(\"frames:\"+str(count))\n",
    "        rate.write(\"\\n\")\n",
    "        rate.write(\"class:\"+vidclass)\n",
    "        rate.close()\n",
    "\n",
    "        #Close the video object\n",
    "        vidcap.release()\n",
    "\n",
    "    print (\"Stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Store Frames\n",
    "framesdir = r\"../FramesFlows\"\n",
    "\n",
    "# path = r\"../UCF-101\"\n",
    "path = r\"E:\\capstone_adbi_data\\UCF-101\"\n",
    "\n",
    "if not os.path.exists(os.path.join(framesdir,splitname)):\n",
    "    os.mkdir(os.path.join(framesdir,splitname))\n",
    "    storeFramesAndFlows(framesdir,splitfiledir,splitfile,splitname)\n",
    "else:\n",
    "    print (\"Frames stored already!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFF(classpath):\n",
    "    frames = list()\n",
    "    xflows = list()\n",
    "    yflows = list()\n",
    "    #Stack up frames and flows\n",
    "    min_frames = float('inf')\n",
    "    min_flows = float('inf')\n",
    "    y_true = None\n",
    "    for folder in os.listdir(classpath):\n",
    "        folderpath = os.path.join(classpath,folder)\n",
    "        # infopath = folderpath\\info.txt\n",
    "        infopath = os.path.join(folderpath,\"info.txt\")\n",
    "        # Read info.txt for extracting class\n",
    "        f = open(infopath,\"r\")\n",
    "        y_true = int(f.readlines()[1].strip().split(':')[1])\n",
    "\n",
    "        # Collect frames\n",
    "        imgpath = os.path.join(folderpath,\"frames\")\n",
    "        flowspath = os.path.join(folderpath,\"flows\")\n",
    "\n",
    "        allframes = os.listdir(imgpath)\n",
    "        allflows = os.listdir(flowspath)\n",
    "        min_frames = min(len(allframes),min_frames)\n",
    "\n",
    "        #Sort frames sequentially\n",
    "        allframes.sort(key = lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "        #Sort flows sequentially\n",
    "        allxflows = list(filter(lambda k: k.split('_')[1] == 'x',allflows))\n",
    "        allyflows = list(filter(lambda k: k.split('_')[1] == 'y',allflows))\n",
    "        allxflows.sort(key = lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        allyflows.sort(key = lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        min_flows = min(len(allxflows),min_flows)\n",
    "\n",
    "        stack = list()\n",
    "        for frame in allframes:\n",
    "            img = cv2.imread(os.path.join(imgpath,frame))\n",
    "            grayimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            grayimg = np.expand_dims(grayimg,axis = 2)\n",
    "            stack.append(grayimg)\n",
    "        frames.append(np.array(stack))\n",
    "        \n",
    "        \n",
    "        #Collect flows\n",
    "        xstack = list()\n",
    "        ystack = list()\n",
    "        for xflow,yflow in zip(allxflows,allyflows):\n",
    "            xfl = cv2.imread(os.path.join(flowspath,xflow))\n",
    "            yfl = cv2.imread(os.path.join(flowspath,yflow))\n",
    "            grayxfl = cv2.cvtColor(xfl,cv2.COLOR_BGR2GRAY)\n",
    "            grayyfl = cv2.cvtColor(yfl,cv2.COLOR_BGR2GRAY)\n",
    "            grayxfl = np.expand_dims(grayxfl,axis = 2)\n",
    "            grayyfl = np.expand_dims(grayyfl,axis = 2)\n",
    "            xstack.append(grayxfl)\n",
    "            ystack.append(grayyfl)\n",
    "        xflows.append(np.array(xstack))\n",
    "        yflows.append(np.array(ystack))\n",
    "\n",
    "    return frames, xflows, yflows, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpath = r\"../FramesFlows/mytest\"\n",
    "frames_dict = dict()\n",
    "xflows_dict = dict()\n",
    "yflows_dict = dict()\n",
    "for each in os.listdir(dfpath):\n",
    "    classpath = os.path.join(dfpath,each)\n",
    "    frames, xflows, yflows, class_name = getFF(classpath)\n",
    "    frames_dict[class_name] = frames\n",
    "    xflows_dict[class_name] = xflows\n",
    "    yflows_dict[class_name] = yflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 224, 224, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary key is the class\n",
    "#Second index represents video number in that class (starting from 0)\n",
    "#Shape shows NO_OF_FRAMES*HEIGHT_OF_IMAGE*WIDTH_OF_IMAGE\n",
    "frames_dict[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided to keep number of segments as 3 for now (consistent with the paper)\n",
    "segments = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data, classes = 101):\n",
    "    \"\"\"\n",
    "    :param data: data to be one hot encoded\n",
    "    :return: np array with one hot encoding\n",
    "    \"\"\"\n",
    "    labels = np.zeros((data.size, classes))\n",
    "    labels[np.arange(data.size), data - 1] = 1\n",
    "    return labels\n",
    "\n",
    "def getSegments(frames_dict,segments=3):\n",
    "    #Get k(equal to segments) random samples(snippets) from frames\n",
    "    framesSegments = defaultdict(list)\n",
    "    ySegments = defaultdict(list)\n",
    "    np.random.seed(0)\n",
    "    for class_name in frames_dict.keys():\n",
    "        videos = frames_dict[class_name]\n",
    "        for video in videos:\n",
    "            vsegs = np.array_split(video,segments)\n",
    "            for x in range(len(vsegs)):\n",
    "                idx = np.random.randint(vsegs[x].shape[0])\n",
    "                #Append random snippet to segments dictionary\n",
    "                framesSegments[x].append(vsegs[x][idx])\n",
    "                ySegments[x].append(class_name)\n",
    "    \n",
    "    #One hot encoding\n",
    "    for x in range(segments):\n",
    "        ySegments[x] = one_hot_encode(np.array(ySegments[x]))\n",
    "\n",
    "    return framesSegments, ySegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesSegments, yFramesTrueSegments = getSegments(frames_dict)\n",
    "xFlowsSegments, yFlowsTrueSegments = getSegments(xflows_dict)\n",
    "yFlowsSegments, yFlowsTrueSegments = getSegments(yflows_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key is segment number(0,1...segments) and second index in the image\n",
    "framesSegments[0][1].shape\n",
    "#key is segment number(0,1,...segments) and second index returns one hot encoded class for the respective image\n",
    "# yFramesTrueSegments[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMixedSegments(x,y):\n",
    "    final = dict()\n",
    "    for key in x.keys():\n",
    "        mylist = list()\n",
    "        for a,b in zip(x[key],y[key]):\n",
    "            new = np.stack((a,b),axis = 2)\n",
    "            new = np.squeeze(new,axis = 3)\n",
    "            mylist.append(new)\n",
    "        final[key] = mylist\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = getMixedSegments(xFlowsSegments, yFlowsSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need separate networks (equal to segments) working in parallel \n",
    "#Parameters for BN-Inception network\n",
    "#We need Inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "imageHeight = 224\n",
    "imageWidth = 224\n",
    "colorChannels = 1\n",
    "num_classes = 101\n",
    "learning_rate = 0.001\n",
    "# X = tf.placeholder(tf.float32,(None,imageHeight,imageWidth,colorChannels))\n",
    "# y = tf.placeholder(tf.float32,(None,num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, filenames, batch_size, ffpath, ftype = \"frames\", segments = 3, test=False):\n",
    "        self.filenames = list()\n",
    "        self.labels = list()\n",
    "        self.batch_size = batch_size\n",
    "        self.folderpath = ffpath\n",
    "        self.ftype = ftype\n",
    "        self.segments = segments\n",
    "        \n",
    "        with open(filenames,\"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                arr = line.split(\" \")\n",
    "                self.filenames.append(arr[0])\n",
    "                self.labels.append(int(arr[1].strip()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)//self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        if self.ftype == \"frames\":\n",
    "            X = defaultdict(list)\n",
    "            Y = defaultdict(list)\n",
    "            for index,each in enumerate(batch_x):\n",
    "                infopath = os.path.join(self.folderpath,each,\"info.txt\")\n",
    "                imgpath = os.path.join(self.folderpath,each,ftype)\n",
    "                f = open(infopath,\"r\")\n",
    "                total_frames = int(f.readlines()[0].strip().split(':')[1])\n",
    "                f.close()\n",
    "                idxs = []\n",
    "                base = total_frames//self.segments\n",
    "                low = 0\n",
    "                for _ in range(segments):\n",
    "                    high = min(low + base, total_frames)\n",
    "                    idxs.append(np.random.randint(low, high,1)[0])\n",
    "                    low = high + 1 \n",
    "                frames = getFrames(idxs, imgpath)\n",
    "                for i in range(segments):\n",
    "                    X[i].append(frames[i])\n",
    "                    Y[i].append(batch_y[index])\n",
    "            \n",
    "        return [np.array(X[key]) for key in X.keys()],[np.array(Y[key]) for key in Y.keys()]\n",
    "    \n",
    "    \n",
    "    def getFrames(self,idxs, imgpath):\n",
    "\n",
    "        stack = list()\n",
    "        for i in idxs:\n",
    "            framename = \"frame_\"+str(i)+\".jpg\"\n",
    "            img = cv2.imread(os.path.join(imgpath,framename))\n",
    "            grayimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            grayimg = np.expand_dims(grayimg,axis = 2)\n",
    "            stack.append(grayimg)\n",
    "            \n",
    "        return np.array(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = \"../ucfTrainTestlist\"\n",
    "filename = \"trainlist01.txt\"\n",
    "dg = dataGenerator(os.path.join(folderpath,filename),128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILE MODEL\n",
    "model = TSN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "model.fit([np.array(framesSegments[0]),np.array(framesSegments[1]),np.array(framesSegments[2]),np.array(flows[0]),np.array(flows[1]),np.array(flows[2])],yFramesTrueSegments[0],batch_size = 3, epochs = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
