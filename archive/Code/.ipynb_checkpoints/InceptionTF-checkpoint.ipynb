{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import inception_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(0.0, stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v2_base(inputs,\n",
    "                      final_endpoint='Mixed_5c',\n",
    "                      min_depth=16,\n",
    "                      depth_multiplier=1.0,\n",
    "                      use_separable_conv=True,\n",
    "                      data_format='NHWC',\n",
    "                      scope=None):\n",
    "  \"\"\"Inception v2 (6a2).\n",
    "  Constructs an Inception v2 network from inputs to the given final endpoint.\n",
    "  This method can construct the network up to the layer inception(5b) as\n",
    "  described in http://arxiv.org/abs/1502.03167.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to. It\n",
    "      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n",
    "      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c', 'Mixed_4a',\n",
    "      'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e', 'Mixed_5a', 'Mixed_5b',\n",
    "      'Mixed_5c'].\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    use_separable_conv: Use a separable convolution for the first layer\n",
    "      Conv2d_1a_7x7. If this is False, use a normal convolution instead.\n",
    "    data_format: Data format of the activations ('NHWC' or 'NCHW').\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    tensor_out: output tensor corresponding to the final_endpoint.\n",
    "    end_points: a set of activations for external use, for example summaries or\n",
    "                losses.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "                or depth_multiplier <= 0\n",
    "  \"\"\"\n",
    "\n",
    "  # end_points will collect relevant activations for external use, for example\n",
    "  # summaries or losses.\n",
    "  end_points = {}\n",
    "\n",
    "  # Used to find thinned depths for each layer.\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n",
    "\n",
    "  if data_format != 'NHWC' and data_format != 'NCHW':\n",
    "    raise ValueError('data_format must be either NHWC or NCHW.')\n",
    "  if data_format == 'NCHW' and use_separable_conv:\n",
    "    raise ValueError(\n",
    "        'separable convolution only supports NHWC layout. NCHW data format can'\n",
    "        ' only be used when use_separable_conv is False.'\n",
    "    )\n",
    "\n",
    "  concat_dim = 3 if data_format == 'NHWC' else 1\n",
    "  with tf.variable_scope(scope, 'InceptionV2', [inputs]):\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "        stride=1,\n",
    "        padding='SAME',\n",
    "        data_format=data_format):\n",
    "\n",
    "      # Note that sizes in the comments below assume an input spatial size of\n",
    "      # 224x224, however, the inputs can be of any size greater 32x32.\n",
    "\n",
    "      # 224 x 224 x 3\n",
    "      end_point = 'Conv2d_1a_7x7'\n",
    "\n",
    "      if use_separable_conv:\n",
    "        # depthwise_multiplier here is different from depth_multiplier.\n",
    "        # depthwise_multiplier determines the output channels of the initial\n",
    "        # depthwise conv (see docs for tf.nn.separable_conv2d), while\n",
    "        # depth_multiplier controls the # channels of the subsequent 1x1\n",
    "        # convolution. Must have\n",
    "        #   in_channels * depthwise_multipler <= out_channels\n",
    "        # so that the separable convolution is not overparameterized.\n",
    "        depthwise_multiplier = min(int(depth(64) / 3), 8)\n",
    "        net = slim.separable_conv2d(\n",
    "            inputs, depth(64), [7, 7],\n",
    "            depth_multiplier=depthwise_multiplier,\n",
    "            stride=2,\n",
    "            padding='SAME',\n",
    "            weights_initializer=trunc_normal(1.0),\n",
    "            scope=end_point)\n",
    "      else:\n",
    "        # Use a normal convolution instead of a separable convolution.\n",
    "        net = slim.conv2d(\n",
    "            inputs,\n",
    "            depth(64), [7, 7],\n",
    "            stride=2,\n",
    "            weights_initializer=trunc_normal(1.0),\n",
    "            scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 112 x 112 x 64\n",
    "      end_point = 'MaxPool_2a_3x3'\n",
    "      net = slim.max_pool2d(net, [3, 3], scope=end_point, stride=2)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 56 x 56 x 64\n",
    "      end_point = 'Conv2d_2b_1x1'\n",
    "      net = slim.conv2d(net, depth(64), [1, 1], scope=end_point,\n",
    "                        weights_initializer=trunc_normal(0.1))\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 56 x 56 x 64\n",
    "      end_point = 'Conv2d_2c_3x3'\n",
    "      net = slim.conv2d(net, depth(192), [3, 3], scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 56 x 56 x 192\n",
    "      end_point = 'MaxPool_3a_3x3'\n",
    "      net = slim.max_pool2d(net, [3, 3], scope=end_point, stride=2)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 28 x 28 x 192\n",
    "      # Inception module.\n",
    "      end_point = 'Mixed_3b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(64), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(32), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 28 x 28 x 256\n",
    "      end_point = 'Mixed_3c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 28 x 28 x 320\n",
    "      end_point = 'Mixed_4a'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(\n",
    "              net, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_0 = slim.conv2d(branch_0, depth(160), [3, 3], stride=2,\n",
    "                                 scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(\n",
    "              branch_1, depth(96), [3, 3], scope='Conv2d_0b_3x3')\n",
    "          branch_1 = slim.conv2d(\n",
    "              branch_1, depth(96), [3, 3], stride=2, scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.max_pool2d(\n",
    "              net, [3, 3], stride=2, scope='MaxPool_1a_3x3')\n",
    "        net = tf.concat(axis=concat_dim, values=[branch_0, branch_1, branch_2])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 14 x 14 x 576\n",
    "      end_point = 'Mixed_4b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(224), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(64), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(\n",
    "              branch_1, depth(96), [3, 3], scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(96), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 14 x 14 x 576\n",
    "      end_point = 'Mixed_4c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(96), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(128), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(96), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 14 x 14 x 576\n",
    "      end_point = 'Mixed_4d'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(160), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(160), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(96), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 14 x 14 x 576\n",
    "      end_point = 'Mixed_4e'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(96), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(160), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(96), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 14 x 14 x 576\n",
    "      end_point = 'Mixed_5a'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(\n",
    "              net, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_0 = slim.conv2d(branch_0, depth(192), [3, 3], stride=2,\n",
    "                                 scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(192), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(256), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(256), [3, 3], stride=2,\n",
    "                                 scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.max_pool2d(net, [3, 3], stride=2,\n",
    "                                     scope='MaxPool_1a_3x3')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 7 x 7 x 1024\n",
    "      end_point = 'Mixed_5b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(352), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(192), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(320), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(160), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(224), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(224), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "      # 7 x 7 x 1024\n",
    "      end_point = 'Mixed_5c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(352), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(\n",
    "              net, depth(192), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(320), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(\n",
    "              net, depth(192), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.09),\n",
    "              scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(224), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(224), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.max_pool2d(net, [3, 3], scope='MaxPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(128), [1, 1],\n",
    "              weights_initializer=trunc_normal(0.1),\n",
    "              scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(\n",
    "            axis=concat_dim, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "        end_points[end_point] = net\n",
    "        if end_point == final_endpoint: return net, end_points\n",
    "    raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
    "\n",
    "\n",
    "def inception_v2(inputs,\n",
    "                 num_classes=1000,\n",
    "                 is_training=True,\n",
    "                 dropout_keep_prob=0.8,\n",
    "                 min_depth=16,\n",
    "                 depth_multiplier=1.0,\n",
    "                 prediction_fn=slim.softmax,\n",
    "                 spatial_squeeze=True,\n",
    "                 reuse=None,\n",
    "                 scope='InceptionV2',\n",
    "                 global_pool=False):\n",
    "  \"\"\"Inception v2 model for classification.\n",
    "  Constructs an Inception v2 network for classification as described in\n",
    "  http://arxiv.org/abs/1502.03167.\n",
    "  The default image size used to train this network is 224x224.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    num_classes: number of predicted classes. If 0 or None, the logits layer\n",
    "      is omitted and the input features to the logits layer (before dropout)\n",
    "      are returned instead.\n",
    "    is_training: whether is training or not.\n",
    "    dropout_keep_prob: the percentage of activation values that are retained.\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    prediction_fn: a function to get predictions out of logits.\n",
    "    spatial_squeeze: if True, logits is of shape [B, C], if false logits is of\n",
    "        shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n",
    "    reuse: whether or not the network and its variables should be reused. To be\n",
    "      able to reuse 'scope' must be given.\n",
    "    scope: Optional variable_scope.\n",
    "    global_pool: Optional boolean flag to control the avgpooling before the\n",
    "      logits layer. If false or unset, pooling is done with a fixed window\n",
    "      that reduces default-sized inputs to 1x1, while larger inputs lead to\n",
    "      larger outputs. If true, any input size is pooled down to 1x1.\n",
    "  Returns:\n",
    "    net: a Tensor with the logits (pre-softmax activations) if num_classes\n",
    "      is a non-zero integer, or the non-dropped-out input to the logits layer\n",
    "      if num_classes is 0 or None.\n",
    "    end_points: a dictionary from components of the network to the corresponding\n",
    "      activation.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "                or depth_multiplier <= 0\n",
    "  \"\"\"\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "\n",
    "  # Final pooling and prediction\n",
    "  with tf.variable_scope(scope, 'InceptionV2', [inputs], reuse=reuse) as scope:\n",
    "    with slim.arg_scope([slim.batch_norm, slim.dropout],\n",
    "                        is_training=is_training):\n",
    "      net, end_points = inception_v2_base(\n",
    "          inputs, scope=scope, min_depth=min_depth,\n",
    "          depth_multiplier=depth_multiplier)\n",
    "      with tf.variable_scope('Logits'):\n",
    "        if global_pool:\n",
    "          # Global average pooling.\n",
    "          net = tf.reduce_mean(net, [1, 2], keep_dims=True, name='global_pool')\n",
    "          end_points['global_pool'] = net\n",
    "        else:\n",
    "          # Pooling with a fixed kernel size.\n",
    "          kernel_size = _reduced_kernel_size_for_small_input(net, [7, 7])\n",
    "          net = slim.avg_pool2d(net, kernel_size, padding='VALID',\n",
    "                                scope='AvgPool_1a_{}x{}'.format(*kernel_size))\n",
    "          end_points['AvgPool_1a'] = net\n",
    "        if not num_classes:\n",
    "          return net, end_points\n",
    "        # 1 x 1 x 1024\n",
    "        net = slim.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
    "        logits = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\n",
    "                             normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        if spatial_squeeze:\n",
    "          logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n",
    "      end_points['Logits'] = logits\n",
    "      end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n",
    "  return logits, end_points\n",
    "inception_v2.default_image_size = 224\n",
    "\n",
    "\n",
    "def _reduced_kernel_size_for_small_input(input_tensor, kernel_size):\n",
    "  \"\"\"Define kernel size which is automatically reduced for small input.\n",
    "  If the shape of the input images is unknown at graph construction time this\n",
    "  function assumes that the input images are is large enough.\n",
    "  Args:\n",
    "    input_tensor: input tensor of size [batch_size, height, width, channels].\n",
    "    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n",
    "  Returns:\n",
    "    a tensor with the kernel size.\n",
    "  TODO(jrru): Make this function work with unknown shapes. Theoretically, this\n",
    "  can be done with the code below. Problems are two-fold: (1) If the shape was\n",
    "  known, it will be lost. (2) inception.slim.ops._two_element_tuple cannot\n",
    "  handle tensors that define the kernel size.\n",
    "      shape = tf.shape(input_tensor)\n",
    "      return = tf.stack([tf.minimum(shape[1], kernel_size[0]),\n",
    "                         tf.minimum(shape[2], kernel_size[1])])\n",
    "  \"\"\"\n",
    "  shape = input_tensor.get_shape().as_list()\n",
    "  if shape[1] is None or shape[2] is None:\n",
    "    kernel_size_out = kernel_size\n",
    "  else:\n",
    "    kernel_size_out = [min(shape[1], kernel_size[0]),\n",
    "                       min(shape[2], kernel_size[1])]\n",
    "  return kernel_size_out\n",
    "\n",
    "\n",
    "inception_v2_arg_scope = inception_utils.inception_arg_scope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
